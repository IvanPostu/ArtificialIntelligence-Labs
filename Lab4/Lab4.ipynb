{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCIM.M.SI - Artificial Intelligence\n",
    "\n",
    "\n",
    "**Lab 2:** Processing Images with OpenCV\n",
    "\\\n",
    "**Performed by:** Postu Ivan SI-181M\n",
    "\\\n",
    "**Verified by:** Gavrilita Mihai\n",
    "\n",
    "## Task 1 - Write the following functions using OpenCV. Adjust the parameters and explain your approach. Plot the initial image and the blurred image in the same plot by using Matplotlib subplots.\n",
    "\n",
    "- A blurring function;\n",
    "\\\n",
    "![Alt text](./r1.png)\n",
    "\\\n",
    "- A sharpening function.\n",
    "\\\n",
    "![Alt text](./r2.png)\n",
    "\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#t1.py\n",
    "def blur_function(image_path, kernel_size=(5,5)):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, kernel_size, 0)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "    axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[1].imshow(blurred, cmap='gray')\n",
    "    axs[1].set_title('Blurred Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def sharpen_function(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(img, -1, kernel)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[1].imshow(cv2.cvtColor(sharpened, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title(\"Sharpened Image\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "blur_function(\"/home/ivan/Desktop/ArtificialIntelligence/Lab4/q1.png\")\n",
    "sharpen_function(\"/home/ivan/Desktop/ArtificialIntelligence/Lab4/q1.png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Implement a face detection system using OpenCV. The function should take as input one image and output the result as the coordinates of the face, in case the image contains a face, or None if the image does not contain any faces. Assume that the image contains no more than one face. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def detect_face(image):\n",
    "    # Load the pre-trained Haar cascades classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply histogram equalization to improve contrast\n",
    "    equalized_image = cv2.equalizeHist(gray_image)\n",
    "\n",
    "    # Detect faces in the image using the Haar cascades classifier\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        equalized_image, scaleFactor=1.3, minNeighbors=5\n",
    "    )\n",
    "\n",
    "    # If no faces are detected, return None\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        face = max(faces, key=lambda x: x[2] * x[3])\n",
    "        x, y, w, h = face\n",
    "        return (x, y, x + w, y + h)\n",
    "\n",
    "\n",
    "image = cv2.imread(\"/home/ivan/Desktop/ArtificialIntelligence/Lab4/person1.png\")\n",
    "\n",
    "face_coords = detect_face(image)\n",
    "\n",
    "# If a face is detected, draw a rectangle around it\n",
    "if face_coords is not None:\n",
    "    x1, y1, x2, y2 = face_coords\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./r3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Implement a system that detects if a photo is accepted for passport or not, by using OpenCV. You can be creative in determining the optimal strategy, but the system should at least follow the listed requirements. \n",
    "- The photo should be colored. You can check that by comparing the RGB values of all the pixels. If the image is gray scale image then the values for each pixel should be equal\n",
    "- The photo should be in portrait orientation or square. Assume that the image given as\n",
    "input is not rotated\n",
    "- The eyes of a subject should be at the same level (with a max error of 5 pixels)\n",
    "- The photo should contain only one person\n",
    "- The head of a person should represent 20% to 50% of the area of the photo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "\n",
    "\n",
    "def is_colored(image):\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Iterate over each pixel and check if it has the same value for all channels\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel = image[y, x]\n",
    "            if not all(pixel == pixel[0]):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_portrait(image):\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Check if the image is portrait or square\n",
    "    if height >= width:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_eyes_at_same_level(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    if len(eyes) != 2:\n",
    "        return False\n",
    "\n",
    "    # Get the y-coordinates of the eyes\n",
    "    y1 = eyes[0][1] + eyes[0][3] // 2\n",
    "    y2 = eyes[1][1] + eyes[1][3] // 2\n",
    "\n",
    "    diff = abs(y1 - y2)\n",
    "\n",
    "    if diff <= 5:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def contains_only_one_person(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    if len(faces) == 1:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def head_area_percentage(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    (x, y, w, h) = faces[0]\n",
    "    top_of_head = y - int(h * 0.25)\n",
    "    head_area = w * int(h * 0.75)\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    head_area_percentage = (head_area / image_area) * 100\n",
    "    return head_area_percentage\n",
    "\n",
    "\n",
    "def is_accepted_for_passport(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    return all(\n",
    "        [\n",
    "            is_colored(image),\n",
    "            is_portrait(image),\n",
    "            is_eyes_at_same_level(image),\n",
    "            contains_only_one_person(image),\n",
    "            head_area_percentage(image),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/home/ivan/Desktop/ArtificialIntelligence/Lab4/test.csv\", newline=\"\"\n",
    ") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\", quotechar='\"')\n",
    "    passed = 0\n",
    "    total = 0\n",
    "    for row in reader:\n",
    "        if row[0] == \"new_path\":\n",
    "            continue\n",
    "\n",
    "        total += 1\n",
    "        img_path = \"/home/ivan/Desktop/ArtificialIntelligence/Lab4/\" + row[0]\n",
    "        expected_value_for_is_accepted_for_passport = bool(row[1])\n",
    "        current_value_for_is_accepted_for_passport = is_accepted_for_passport(img_path)\n",
    "        if current_value_for_is_accepted_for_passport:\n",
    "            passed += 1\n",
    "        print(\n",
    "            row[0],\n",
    "            expected_value_for_is_accepted_for_passport,\n",
    "            current_value_for_is_accepted_for_passport,\n",
    "        )\n",
    "    print(f\"Accuracy: {passed / total * 100}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
